{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture Overview\n",
    "\n",
    "***\n",
    "\n",
    "### 1.1 Encoder-Decoder Model\n",
    "\n",
    "- _Source_ : [Seq2Seq documentation](https://google.github.io/seq2seq/)\n",
    "\n",
    "#### 1.1.1 Encoder-decoder overview\n",
    "\n",
    "- __Encoder__ :\n",
    "    * Reads in source data, produces feature representation in cts space\n",
    "        * RNN; input sequence of words $\\to$ fixed vector that is $\\approx$ meaning\n",
    "        * CNN; input img $\\to$ volume that contains higher-level features of img\n",
    "    * _Idea_ : representation from encoder used by decoder to generate new data\n",
    "    * [_List of encoders_](https://google.github.io/seq2seq/encoders/)\n",
    "    \n",
    "- __Decoder__ :\n",
    "    * Generative model, conditioned on representation from encoder\n",
    "        * RNN decoder: learns to generate translation for encoded sequence in another language\n",
    "    * [_List of decoders_](https://google.github.io/seq2seq/decoders/)\n",
    "    \n",
    "#### 1.1.2 Encoder-decoder model\n",
    "    \n",
    "- __The model__ :\n",
    "    * Defines how encoder/decoder put together & how to calculate/minimize loss fn\n",
    "    * [_List of models_](https://google.github.io/seq2seq/models/)\n",
    "    \n",
    "    <img src = \"img/google_brain_encoder_decoder.png\" style = \"width: 500px\"/>\n",
    "\n",
    "### 1.2 RNN: Recurrent Neural Network\n",
    "- _Sources_ : \n",
    "    - $[1]$ [RNN Wiki](https://en.wikipedia.org/wiki/Recurrent_neural_network)\n",
    "    - $[2]$ [Coursera Slides](https://cs230.stanford.edu/files/C5M1.pdf)\n",
    "    - $[3]$ [Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/pdf/1703.03906.pdf) (Google Brain)\n",
    "\n",
    "#### 1.2.1 Overview $[1]$\n",
    "- _Problems with standard NN_ :\n",
    "    - Inputs, outputs can be different lengths\n",
    "    - Doesn't share features learned across different positions of text\n",
    "- Connections between nodes form directed graph along temporal sequence; allows temporal dynamic behavior\n",
    "- Two classes of RNNs:\n",
    "    1. _Finite impulse_ : response to input is of finite duration (settles to zero in finite time)\n",
    "        - Is DAG, can be \"unrolled\" and replaced with strictly feedforward NN\n",
    "    2. _Infinite impulse_ : may have internal feedback, and may continue to respond indefinitely (although usually decay)\n",
    "        - Directed cyclic graph, cannot be unrolled\n",
    "- Can have additional stored states, potentially controlled by NN $\\to$ incorporating time delays/feedback loops leads to LSTM gated memory principles\n",
    "\n",
    "#### 1.2.2 RNN types $[2]$\n",
    "\n",
    "<img src = \"img/coursera_rnn_types.png\" style = \"width: 500px\"/>\n",
    "\n",
    "#### 1.2.3 Issue of vanishing gradients, illustrated $[2]$\n",
    "\n",
    "<img src = \"img/coursera_vanishing_grads.png\" style = \"width: 500px\"/>\n",
    "    \n",
    "\n",
    "#### 1.2.4 GRU: gated recurrent unit\n",
    "- Gating mechanism in RNN: like LSTM with forget gate, but has fewer parameters (lacks output gate)\n",
    "- Also addresses the vanishing gradients problem\n",
    "- Can have better performance than LSTM on small datasets; but LSTM strictly stronger $[3]$ \n",
    "\n",
    "### 1.3 LSTM: Long Short-Term Memory\n",
    "\n",
    "- _Sources_ : \n",
    "    - $[1]$ [Long Short-Term Memory](https://www.bioinf.jku.at/publications/older/2604.pdf) \n",
    "        - Original paper on LSTM, cited in Coursera\n",
    "    - $[2]$ [LSTM Wiki](https://en.wikipedia.org/wiki/Long_short-term_memory)\n",
    "    - $[3]$ [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/pdf/1409.3215.pdf)\n",
    "\n",
    "#### 1.3.1 Motivation $[1]$\n",
    "- DNNs can only be applied to poblems where inputs, targets encoded with vectors of fixed dimensionality; not good for speech\n",
    "- Conventional DNNs have issue of compounding error in backprop\n",
    "- _LSTM soln_ : when error values back-propagated, error remains in LSTM cell $\\implies$ \"error carousel\" feeds error back into each of LSTM gates, until they learn to cut off value\n",
    "\n",
    "\n",
    "#### 1.3.2 What is an LSTM? $[1, \\, 2]$\n",
    "- Has feedback connections, unlike standard _feedforward_ NNs; in feedforward, node connections don't form a cycle\n",
    "- _Idea_ :\n",
    "    - Cell remembers values, and three gates regulate flow of into into/out of cell\n",
    "    - Useful for data with lags\n",
    "    - Each gate has activation: marked increase in number of parameters\n",
    "    - Robustness to range of parameters due to error control\n",
    "    \n",
    "#### 1.3.3 LSTM units $[1]$\n",
    "- _LSTM unit_ :  \n",
    "    - __Cell__ : keeps track of dependencies between elements in input sequence\n",
    "    - __Input gate__ : controls net flow into cell\n",
    "    - __Forget gate__ : controls how much value remains in cell\n",
    "    - __Output gate__ : controls extent to which cell value used to compute activation\n",
    "- _Why gate units?_ :\n",
    "    - Avoids weight conflicts\n",
    "    - Input gate learns when to release errors by appropriate scaling\n",
    "    \n",
    "<img src = \"img/coursera_lstm.png\" style = \"width: 500px\"/>    \n",
    "    \n",
    "#### 1.3.4 Application to NLP models $[3]$\n",
    "- _Property of LSTM_ : learns to map input sentence of variable length onto fixed-dimensional vector representation\n",
    "    - Translation objective encourages LSTM to find sentence representations that capture meaning\n",
    "    - Paper claim: model aware of word order and fairly invariant to active/passive voice\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generalized Models\n",
    "\n",
    "***\n",
    "\n",
    "### 2.1 Seq2Seq\n",
    "\n",
    "- _Sources_ : \n",
    "    - [Seq2Seq documentation](https://google.github.io/seq2seq/)\n",
    "    - [Wiki](https://en.wikipedia.org/wiki/Seq2seq)\n",
    "\n",
    "#### 2.1.1 Model Overview\n",
    "- Turns one sequence into another; uses RNN, LSTM, or GRU\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Paper Implementations: Non-Parallel Corpora\n",
    "\n",
    "***\n",
    "\n",
    "### 3.1 [Style Transfer from Non-Parallel Text by Cross-Alignment](https://arxiv.org/pdf/1705.09655.pdf)\n",
    "\n",
    "#### 3.1.1 Introduction\n",
    "- Learn encoder $\\to$ take style as input $\\to$ map to style-independent content\n",
    "- Do not use VAE ( _need to research_ ) - need to preserve latent content\n",
    "\n",
    "<img src = \"img/non_parallel_model.png\" style = \"width: 500px\"/>  \n",
    "\n",
    "- Task evaluation:\n",
    "    1. Sentiment modification\n",
    "    2. Decipherment of word substitution ciphers\n",
    "    3. Recovery of word order\n",
    "    \n",
    "#### 3.1.2 Related work\n",
    "- _Vision_ : cannot employ many similar vision methods due to discreteness of NLP\n",
    "- [Toward Controlled Generation of Text](https://arxiv.org/pdf/1703.00955.pdf):\n",
    "    - Generating sentences with controllable attributes by learning disentangled latent representations\n",
    "- [InfoGAN: Representation Learning](https://arxiv.org/pdf/1606.03657.pdf)\n",
    "    - More on latent spaes\n",
    "    \n",
    "#### 3.1.3 Formulation\n",
    "- _Motivation_ : want to recover joint distributions of style in order to facilitate style transfer\n",
    "    - __Claim__ : datasets from different styles need to be distinct enough for this paper's methods to work\n",
    "- _Conclusions_ : latent content should have most complexity from input, and latent style variable should have simple effects\n",
    "\n",
    "#### 3.1.4 Model\n",
    "- Use of auto-encoder model:\n",
    "    1. Encoding step to infer content of target\n",
    "    2. Decoding step to generate transferred counterpart\n",
    "- Need content space of source and target to coincide; could employ VAE\n",
    "    - Probabilistic VAE: [Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114.pdf)\n",
    "- _Proposed models_ :\n",
    "    1. __Aligned auto-encoder__ :\n",
    "        - Implement encoder & decoder using single-layer RNNs with GRU\n",
    "        - E: takes input x, outputs content z\n",
    "        - G: generates sentence x conditioned on latent state\n",
    "        - Adversarial discriminator D\n",
    "        - Need to align distributions: use discriminator D as feed-forward NN with single hidden layer, sigmoid output\n",
    "        - Complicated loss function!\n",
    "    2. __Cross-aligned auto-encoder__ :\n",
    "        - Aligns transferred samples from one style with true samples from other\n",
    "        \n",
    "#### 3.1.5 Implementation\n",
    "- Used model-based evaluation metric for sentiment modification: measure how often a transferred sentence has correct sentiment according to pre-trained sentiment classifier\n",
    "    - See [CNN for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf), [word2vec](https://code.google.com/archive/p/word2vec/)\n",
    "    \n",
    "***\n",
    "\n",
    "### 3.2 [Disentangled Representation Learning for Non-Parallel Text Style Transfer](https://arxiv.org/pdf/1808.04339.pdf)\n",
    "\n",
    "***\n",
    "\n",
    "### 3.3 [Neural Style Transfer for Non-Parallel Text](https://github.com/vinitra/neural-text-style-transfer/blob/master/reports/Neural_Style_Transfer_for_Non_Parallel_Text.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
